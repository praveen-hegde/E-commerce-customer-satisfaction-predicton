{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from math import radians\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import confusion_matrix,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Function which gives predicted review_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(x):\n",
    "    \n",
    "    \"\"\"This function takes single query point as input \n",
    "        and \n",
    "       preprocess,featurize itand finally gives the predicted target score\"\"\"\n",
    "    \n",
    "    ##### Convert to datetime type ####\n",
    "    x[\"order_purchase_timestamp\"] = pd.to_datetime(x[\"order_purchase_timestamp\"])\n",
    "    x[\"order_approved_at\"] = pd.to_datetime(x[\"order_approved_at\"])\n",
    "    x[\"order_delivered_carrier_date\"] = pd.to_datetime(x[\"order_delivered_carrier_date\"])\n",
    "    x[\"order_delivered_customer_date\"] = pd.to_datetime(x[\"order_delivered_customer_date\"])\n",
    "    x[\"order_estimated_delivery_date\"] = pd.to_datetime(x[\"order_estimated_delivery_date\"])\n",
    "    x[\"shipping_limit_date\"] = pd.to_datetime(x[\"shipping_limit_date\"])\n",
    "\n",
    "    \n",
    "    ################################ BASIC FEATURES ########################################\n",
    "    #### Time based features #####\n",
    "    #Time of estimated delivery\n",
    "    x[\"estimated_time\"] = round((x[\"order_estimated_delivery_date\"]-x[\"order_purchase_timestamp\"]).total_seconds()/3600,6)\n",
    "    #Time taken for delivery\n",
    "    x[\"actual_time\"]    = round((x[\"order_delivered_customer_date\"]-x[\"order_purchase_timestamp\"]).total_seconds()/3600,6)\n",
    "    #Difference between actual delivery time and estimated delivery time\n",
    "    x[\"diff_actual_estimated\"]   = round((x[\"order_delivered_customer_date\"]-x[\"order_estimated_delivery_date\"]).total_seconds()/3600,6)\n",
    "    # difference between purchase time and approved time\n",
    "    x[\"diff_purchased_approved\"] = round((x[\"order_approved_at\"]-x[\"order_purchase_timestamp\"]).total_seconds()/3600,6)\n",
    "    # difference between purchase time and courrier delivery time\n",
    "    x[\"diff_purchased_courrier\"] = round((x[\"order_delivered_carrier_date\"]-x[\"order_purchase_timestamp\"]).total_seconds()/3600,6)\n",
    "    \n",
    "    # some more features from timestamp(days, weekday, month, hour)\n",
    "    x[\"delivery_day\"]   = x[\"order_delivered_customer_date\"].weekday()\n",
    "    x[\"delivery_date\"]  = x[\"order_delivered_customer_date\"].day\n",
    "    x[\"delivery_month\"] = x[\"order_delivered_customer_date\"].month\n",
    "    x[\"delivery_hour\"]  = x[\"order_delivered_customer_date\"].hour\n",
    "\n",
    "    x[\"purchased_day\"]   = x[\"order_purchase_timestamp\"].weekday()\n",
    "    x[\"purchased_date\"]  = x[\"order_purchase_timestamp\"].day\n",
    "    x[\"purchased_month\"] = x[\"order_purchase_timestamp\"].month\n",
    "    x[\"purchased_hour\"]  = x[\"order_purchase_timestamp\"].hour\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######## Distance based features ###############\n",
    "    ### Distance between customer and seller ####\n",
    "    cust_loc   = np.array([radians(x.lat_customer),radians(x.lng_customer)])\n",
    "    seller_loc = np.array([radians(x.lat_seller),radians(x.lng_seller)])\n",
    "    \n",
    "    dist = haversine_distances([cust_loc, seller_loc])*6371\n",
    "    x[\"distance\"] = dist[0,1]\n",
    "    \n",
    "    ### Speed \n",
    "    x[\"speed\"] = x[\"distance\"]/x[\"actual_time\"]\n",
    "    \n",
    "    ### Binary features like same city or not, same state or not ###\n",
    "    ### same state\n",
    "    x[\"same_state\"] = 1 if (x.customer_state == x.seller_state) else 0\n",
    "    \n",
    "    ### same city \n",
    "    x[\"customer_city\"] = unidecode(x[\"customer_city\"].lower())\n",
    "    x[\"seller_city\"] = unidecode(x[\"seller_city\"].lower())\n",
    "    \n",
    "    x[\"same_city\"]   = 1 if (x.customer_city == x.seller_city) else 0\n",
    "    \n",
    "    ### late_shipping\n",
    "    \n",
    "    x[\"late_shipping\"] = 1 if (x.shipping_limit_date < x.order_delivered_carrier_date) else 0\n",
    "    \n",
    "    ### high_freight\n",
    "    x[\"high_freight\"]  = 1 if (x.price < x.freight_value) else 0\n",
    "    \n",
    "    ### size of the product\n",
    "    x[\"size\"] = x[\"product_length_cm\"]*x[\"product_height_cm\"]*x[\"product_width_cm\"]\n",
    "    \n",
    "    ########################## ADVANCED FEATURES ######################################\n",
    "    ################# customer_seller similarity based on order_item_id ###############\n",
    "    order_seller = pd.read_pickle(\"order_seller_table.pkl\")\n",
    "    total_order_id = pd.read_pickle(\"total_order_id.pkl\")\n",
    "    total_seller_id = pd.read_pickle(\"total_seller_id.pkl\")\n",
    "    user_order = pd.read_pickle(\"user_order_table.pkl\")\n",
    "    user_total = pd.read_pickle(\"user_total.pkl\")\n",
    "    order_total = pd.read_pickle(\"order_total.pkl\")\n",
    "    \n",
    "    x[\"seller_share\"] = order_seller.loc[(x[\"order_item_id\"],x[\"seller_id\"])]/total_order_id[x[\"order_item_id\"]]\n",
    "    x[\"bs_share\"]     = order_seller.loc[(x[\"order_item_id\"],x[\"seller_id\"])]/total_seller_id[x[\"seller_id\"]]\n",
    "    \n",
    "    x[\"cust_share\"]   = user_order.loc[(x[\"order_item_id\"],x[\"customer_unique_id\"])]/order_total[x[\"order_item_id\"]]\n",
    "    x[\"bu_share\"]     = user_order.loc[(x[\"order_item_id\"],x[\"customer_unique_id\"])]/user_total[x[\"customer_unique_id\"]]\n",
    "    \n",
    "    ### similarity\n",
    "    x[\"similarity\"]   = np.dot([x[\"seller_share\"],x[\"bs_share\"]] , [x[\"cust_share\"],x[\"bu_share\"]])\n",
    "    \n",
    "    ######################## customer_seller similarity based on category_name ###############\n",
    "    cat_seller = pd.read_pickle(\"cat_seller_table.pkl\")\n",
    "    total_cat_order_id = pd.read_pickle(\"total_cat_order_id.pkl\")\n",
    "    total_cat_seller_id = pd.read_pickle(\"total_cat_seller_id.pkl\")\n",
    "    user_cat = pd.read_pickle(\"user_cat_table.pkl\")\n",
    "    user_cat_total = pd.read_pickle(\"user_cat_total.pkl\")\n",
    "    order_cat_total = pd.read_pickle(\"order_cat_total.pkl\")\n",
    "    \n",
    "    x[\"seller_category_share\"] = cat_seller.loc[(x[\"product_category_name\"],x[\"seller_id\"])]/total_cat_order_id[x[\"product_category_name\"]]\n",
    "    x[\"cat_seller_share\"]      = cat_seller.loc[(x[\"product_category_name\"],x[\"seller_id\"])]/total_cat_seller_id[x[\"seller_id\"]]\n",
    "\n",
    "    x[\"cust_category_share\"]   = user_cat.loc[(x[\"product_category_name\"],x[\"customer_unique_id\"])]/order_cat_total[x[\"product_category_name\"]]\n",
    "    x[\"cat_cust_share\"]        = user_cat.loc[(x[\"product_category_name\"],x[\"customer_unique_id\"])]/user_cat_total[x[\"customer_unique_id\"]]\n",
    "\n",
    "    ### similarity\n",
    "    x[\"similarity_using_cat\"]  = np.dot([x[\"seller_category_share\"],x[\"cat_seller_share\"]],[x[\"cust_category_share\"],x[\"cat_cust_share\"]])\n",
    "    ############################################################################################\n",
    "    ########### Total customers for each seller and total seller for each customer #############\n",
    "    dict_seller = pd.read_pickle('dict_seller.pkl')\n",
    "    dict_customer = pd.read_pickle('dict_customer.pkl')\n",
    "    dict_seller_order = pd.read_pickle(\"dict_seller_order.pkl\")\n",
    "    \n",
    "    x[\"num_of_customers_for_seller\"] = dict_seller[x[\"seller_id\"]]\n",
    "    x[\"num_of_sellers_for_cust\"]     = dict_customer[x[\"customer_unique_id\"]]\n",
    "    x[\"total_order_for_seller\"]      = dict_seller_order[x[\"seller_id\"]]\n",
    "    \n",
    "#################################################################################################\n",
    "    label = joblib.load(\"seller_id_encode.pkl\")\n",
    "    x[\"seller_id_label\"] = label.transform([x[\"seller_id\"]])\n",
    "    \n",
    "    label = joblib.load(\"product_id_encode.pkl\")\n",
    "    x[\"product_id_label\"] = label.transform([x[\"product_id\"]])\n",
    "    #################################################\n",
    "    ############## countvectorizers ################\n",
    "    ### payment_type\n",
    "    vec = joblib.load(\"count_vect_payment_1.pkl\")\n",
    "    x_te_pay_type = vec.transform([x[\"payment_type\"]])\n",
    "    #### order_item_id\n",
    "    x[\"order_item_id\"] = x[\"order_item_id\"].astype(str)\n",
    "    vec = joblib.load(\"count_vect_item_1.pkl\")\n",
    "    x_te_id = vec.transform([x[\"order_item_id\"]])\n",
    "    ### product_category_name\n",
    "    vec = joblib.load(\"count_vect_cat_1.pkl\")\n",
    "    x_te_cat = vec.transform([x[\"product_category_name\"]])\n",
    "    ####################################################\n",
    "    ############### standardization ####################\n",
    "    num = x[[\"payment_sequential\",\"payment_installments\",\"payment_value\",\"seller_id_label\",\"product_id_label\",\"seller_share\",\"bu_share\",\n",
    "              \"bs_share\",\"cust_share\",\n",
    "          \"lat_customer\",\"lng_customer\",\"lat_seller\",\"lng_seller\",\"product_name_lenght\",\"product_description_lenght\",\n",
    "           \"product_photos_qty\",\"product_weight_g\",\"size\",\"price\",\"delivery_day\",\"delivery_date\",\"delivery_month\",\n",
    "              \"delivery_hour\",\"purchased_day\",\"purchased_date\",\"purchased_month\",\"purchased_hour\",\"num_of_customers_for_seller\",\n",
    "              \"num_of_sellers_for_cust\",\"total_order_for_seller\",\n",
    "           \"freight_value\",\"estimated_time\",\"actual_time\",\"diff_actual_estimated\",\"diff_purchased_approved\",\n",
    "           \"diff_purchased_courrier\",\"distance\",\"speed\",\"similarity\",\"similarity_using_cat\"]]\n",
    "    \n",
    "    norm = joblib.load(\"std_num_1.pkl\")\n",
    "    num = np.array(num).reshape(1,-1)\n",
    "    x_te_num = norm.transform(num)\n",
    "    #################################################################\n",
    "    ######## concatenate all features to create query point #########\n",
    "    query_point = hstack((x_te_pay_type,x_te_id,x_te_cat,x_te_num,x.same_state,\n",
    "                              x.same_city,x.late_shipping,x.high_freight)).toarray()\n",
    "    \n",
    "    ##################################################################\n",
    "    model = joblib.load(\"binary_model.pkl\")\n",
    "    if model.predict(query_point) == 1:\n",
    "        prediction = 5\n",
    "        \n",
    "    else:\n",
    "        ################ CUSTOM ENSEMBLE ##########################\n",
    "        label = joblib.load(\"seller_encode_2.pkl\")\n",
    "        x[\"seller_id_enc\"] = label.transform([x[\"seller_id\"]])\n",
    "    \n",
    "        label = joblib.load(\"product_encode_2.pkl\")\n",
    "        x[\"product_id_enc\"] = label.transform([x[\"product_id\"]])\n",
    "        ####\n",
    "        ######## countvectorizers ###########\n",
    "        ### payment_type\n",
    "        vec = joblib.load(\"countvec_pay_2.pkl\")\n",
    "        x_te_pay_type = vec.transform([x[\"payment_type\"]])\n",
    "        \n",
    "        #### order_item_id\n",
    "        x[\"order_item_id\"] = x[\"order_item_id\"].astype(str)\n",
    "        vec = joblib.load(\"countvec_item_2.pkl\")\n",
    "        x_te_id = vec.transform([x[\"order_item_id\"]])\n",
    "        \n",
    "        ### product_category_name\n",
    "        vec = joblib.load(\"countvec_cat_2.pkl\")\n",
    "        x_te_cat = vec.transform([x[\"product_category_name\"]])\n",
    "        \n",
    "        ####################################################\n",
    "        ############### standardization ####################\n",
    "        num = x[[\"payment_sequential\",\"payment_installments\",\"payment_value\",\"seller_id_enc\",\"product_id_enc\",\"seller_share\",\"bu_share\",\n",
    "                 \"bs_share\",\"cust_share\",\n",
    "                 \"lat_customer\",\"lng_customer\",\"lat_seller\",\"lng_seller\",\"product_name_lenght\",\"product_description_lenght\",\n",
    "                 \"product_photos_qty\",\"product_weight_g\",\"size\",\"price\",\"delivery_day\",\"delivery_date\",\"delivery_month\",\n",
    "                 \"delivery_hour\",\"purchased_day\",\"purchased_date\",\"purchased_month\",\"purchased_hour\",\"num_of_customers_for_seller\",\n",
    "                 \"num_of_sellers_for_cust\",\"total_order_for_seller\",\n",
    "                 \"freight_value\",\"estimated_time\",\"actual_time\",\"diff_actual_estimated\",\"diff_purchased_approved\",\n",
    "                 \"diff_purchased_courrier\",\"distance\",\"speed\",\"similarity\",\"similarity_using_cat\"]]\n",
    "    \n",
    "        norm = joblib.load(\"std_num_2.pkl\")\n",
    "        num = np.array(num).reshape(1,-1)\n",
    "        x_te_num = norm.transform(num)\n",
    "        #################################################################\n",
    "        ######## concatenate all features to create query point #########\n",
    "        query_point = hstack((x_te_pay_type,x_te_id,x_te_cat,x_te_num,x.same_state,\n",
    "                              x.same_city,x.late_shipping,x.high_freight)).toarray()\n",
    "        \n",
    "        models = joblib.load(\"base_models.pkl\")\n",
    "        predicts = []\n",
    "        for model in models:\n",
    "            predicts.append(model.predict(query_point))\n",
    "        predicts = np.array(predicts).reshape(1,-1)\n",
    "        \n",
    "        meta_clf = joblib.load(\"meta_clf.pkl\")\n",
    "        prediction = meta_clf.predict(predicts)\n",
    "        \n",
    "###############################################################################################################        \n",
    "        \n",
    "    return prediction     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Function which calculates Macro F1 scores for given set of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(x,y):\n",
    "    \n",
    "    \"\"\"This function takes dataset as input \n",
    "        and \n",
    "       preprocess,featurize itand finally gives the predicted target score and calculates the macro F1 score\"\"\"\n",
    "    \n",
    "    ##### Convert to datetime type ####\n",
    "    x[\"order_purchase_timestamp\"] = pd.to_datetime(x[\"order_purchase_timestamp\"])\n",
    "    x[\"order_approved_at\"] = pd.to_datetime(x[\"order_approved_at\"])\n",
    "    x[\"order_delivered_carrier_date\"] = pd.to_datetime(x[\"order_delivered_carrier_date\"])\n",
    "    x[\"order_delivered_customer_date\"] = pd.to_datetime(x[\"order_delivered_customer_date\"])\n",
    "    x[\"order_estimated_delivery_date\"] = pd.to_datetime(x[\"order_estimated_delivery_date\"])\n",
    "    x[\"shipping_limit_date\"] = pd.to_datetime(x[\"shipping_limit_date\"])\n",
    "\n",
    "    \n",
    "    ################################ BASIC FEATURES ########################################\n",
    "    #### Time based features #####\n",
    "    #Time of estimated delivery\n",
    "    x[\"estimated_time\"] = (x[\"order_estimated_delivery_date\"]-x[\"order_purchase_timestamp\"]).apply(\n",
    "                                                                                     lambda x: x.total_seconds()/3600)\n",
    "    #Time taken for delivery\n",
    "    x[\"actual_time\"]    = (x[\"order_delivered_customer_date\"]-x[\"order_purchase_timestamp\"]).apply(\n",
    "                                                                                     lambda x: x.total_seconds()/3600)\n",
    "    #Difference between actual delivery time and estimated delivery time\n",
    "    x[\"diff_actual_estimated\"]   = (x[\"order_delivered_customer_date\"]-x[\"order_estimated_delivery_date\"]).apply(\n",
    "                                                                                     lambda x: x.total_seconds()/3600)\n",
    "    # difference between purchase time and approved time\n",
    "    x[\"diff_purchased_approved\"] = (x[\"order_approved_at\"]-x[\"order_purchase_timestamp\"]).apply(\n",
    "                                                                                     lambda x: x.total_seconds()/3600)\n",
    "    # difference between purchase time and courrier delivery time\n",
    "    x[\"diff_purchased_courrier\"] = (x[\"order_delivered_carrier_date\"]-x[\"order_purchase_timestamp\"]).apply(\n",
    "                                                                                     lambda x: x.total_seconds()/3600)\n",
    "    \n",
    "    # some more features from timestamp(days, weekday, month, hour)\n",
    "    x[\"delivery_day\"]   = x[\"order_delivered_customer_date\"].apply(lambda x: x.weekday())\n",
    "    x[\"delivery_date\"]  = x[\"order_delivered_customer_date\"].apply(lambda x: x.day)\n",
    "    x[\"delivery_month\"] = x[\"order_delivered_customer_date\"].apply(lambda x: x.month)\n",
    "    x[\"delivery_hour\"]  = x[\"order_delivered_customer_date\"].apply(lambda x: x.hour)\n",
    "\n",
    "    x[\"purchased_day\"]   = x[\"order_purchase_timestamp\"].apply(lambda x: x.weekday())\n",
    "    x[\"purchased_date\"]  = x[\"order_purchase_timestamp\"].apply(lambda x: x.day)\n",
    "    x[\"purchased_month\"] = x[\"order_purchase_timestamp\"].apply(lambda x: x.month)\n",
    "    x[\"purchased_hour\"]  = x[\"order_purchase_timestamp\"].apply(lambda x: x.hour)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######## Distance based features ###############\n",
    "    ### Distance between customer and seller ####\n",
    "    X = []  # list to store customer latitude and longitude\n",
    "    Y = []  # list to store seller latitude and longitude\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        X.append([radians(x.lat_customer[i]),radians(x.lng_customer[i])])\n",
    "        Y.append([radians(x.lat_seller[i]),radians(x.lng_seller[i])])\n",
    "    \n",
    "    #converting to numpy array    \n",
    "    cust_loc = np.array(X)\n",
    "    seller_loc = np.array(Y)\n",
    "    \n",
    "    distance=[]\n",
    "    for i in range(len(x)):\n",
    "        #calculating distance and multiplying by radius of earth(6371) to get distance in km\n",
    "        dist = haversine_distances([cust_loc[i], seller_loc[i]])*6371\n",
    "        distance.append(dist[0,1])\n",
    "    \n",
    "    x[\"distance\"] = distance\n",
    "    \n",
    "    ### Speed \n",
    "    x[\"speed\"] = x[\"distance\"]/x[\"actual_time\"]\n",
    "    \n",
    "    ### Binary features like same city or not, same state or not ###\n",
    "    ### same state\n",
    "    same = []\n",
    "    for i in range(len(x)):\n",
    "        if x.customer_state[i] == x.seller_state[i]:\n",
    "            same.append(1)\n",
    "        else:\n",
    "            same.append(0)\n",
    "        \n",
    "    x[\"same_state\"] = same\n",
    "    \n",
    "    ### same city \n",
    "    x['customer_city'] = x.apply(lambda row: unidecode(row['customer_city'].lower()), axis=1)\n",
    "    x['seller_city']   = x.apply(lambda row: unidecode(row['seller_city'].lower()), axis=1)\n",
    "    \n",
    "    same = []\n",
    "    for i in range(len(x)):\n",
    "        if x.customer_city[i] == x.seller_city[i]:\n",
    "            same.append(1)\n",
    "        else:\n",
    "            same.append(0)\n",
    "\n",
    "    x[\"same_city\"] = same\n",
    "    \n",
    "    ### late_shipping\n",
    "    late = []\n",
    "    for i in range(len(x)):\n",
    "        if x.shipping_limit_date[i] < x.order_delivered_carrier_date[i]:\n",
    "            late.append(1)\n",
    "        else:\n",
    "            late.append(0)\n",
    "        \n",
    "    x[\"late_shipping\"] = late\n",
    "    \n",
    "    ### high_freight\n",
    "    high = []\n",
    "    for i in range(len(x)):\n",
    "        if x.price[i] < x.freight_value[i]:\n",
    "            high.append(1)\n",
    "        else:\n",
    "            high.append(0)\n",
    "        \n",
    "    x[\"high_freight\"] = high\n",
    "    \n",
    "    ### size of the product\n",
    "    x[\"size\"] = x[\"product_length_cm\"]*x[\"product_height_cm\"]*x[\"product_width_cm\"]\n",
    "    \n",
    "    ########################## ADVANCED FEATURES ######################################\n",
    "    ################# customer_seller similarity based on order_item_id ###############\n",
    "    order_seller = pd.read_pickle(\"order_seller_table.pkl\")\n",
    "    total_order_id = pd.read_pickle(\"total_order_id.pkl\")\n",
    "    total_seller_id = pd.read_pickle(\"total_seller_id.pkl\")\n",
    "    user_order = pd.read_pickle(\"user_order_table.pkl\")\n",
    "    user_total = pd.read_pickle(\"user_total.pkl\")\n",
    "    order_total = pd.read_pickle(\"order_total.pkl\")\n",
    "    \n",
    "    seller_share = []\n",
    "    bs_share = []\n",
    "    for i in range(len(x)):\n",
    "        seller_share.append((order_seller.loc[(x[\"order_item_id\"][i],x[\"seller_id\"][i])]/total_order_id[x[\"order_item_id\"][i]]))\n",
    "        bs_share.append((order_seller.loc[(x[\"order_item_id\"][i],x[\"seller_id\"][i])]/total_seller_id[x[\"seller_id\"][i]]))\n",
    "\n",
    "    x[\"seller_share\"] = seller_share\n",
    "    x[\"bs_share\"] = bs_share\n",
    "    \n",
    "    cust_share = []\n",
    "    bu_share = []\n",
    "    for i in range(len(x)):\n",
    "    \n",
    "        cust_share.append((user_order.loc[(x[\"order_item_id\"][i],x[\"customer_unique_id\"][i])]/order_total[x[\"order_item_id\"][i]]))\n",
    "    \n",
    "        bu_share.append((user_order.loc[(x[\"order_item_id\"][i],x[\"customer_unique_id\"][i])]/user_total[x[\"customer_unique_id\"][i]]))\n",
    "    \n",
    "    x[\"cust_share\"] = cust_share\n",
    "    x[\"bu_share\"] = bu_share\n",
    "    \n",
    "    ### similarity\n",
    "    similarity = []\n",
    "    for i in range(len(x)):\n",
    "         similarity.append((np.dot([x[\"seller_share\"][i],x[\"bs_share\"][i]] , [x[\"cust_share\"][i],x[\"bu_share\"][i]])))\n",
    "        \n",
    "    x[\"similarity\"] = similarity\n",
    "    \n",
    "    ######################## customer_seller similarity based on category_name ###############\n",
    "    cat_seller = pd.read_pickle(\"cat_seller_table.pkl\")\n",
    "    total_cat_order_id = pd.read_pickle(\"total_cat_order_id.pkl\")\n",
    "    total_cat_seller_id = pd.read_pickle(\"total_cat_seller_id.pkl\")\n",
    "    user_cat = pd.read_pickle(\"user_cat_table.pkl\")\n",
    "    user_cat_total = pd.read_pickle(\"user_cat_total.pkl\")\n",
    "    order_cat_total = pd.read_pickle(\"order_cat_total.pkl\")\n",
    "    \n",
    "    seller_share = []\n",
    "    bs_share = []\n",
    "    for i in range(len(x)):\n",
    "        seller_share.append((cat_seller.loc[(x[\"product_category_name\"][i],x[\"seller_id\"][i])]/total_cat_order_id[x[\"product_category_name\"][i]]))\n",
    "        bs_share.append((cat_seller.loc[(x[\"product_category_name\"][i],x[\"seller_id\"][i])]/total_cat_seller_id[x[\"seller_id\"][i]]))\n",
    "\n",
    "    x[\"seller_category_share\"] = seller_share\n",
    "    x[\"cat_seller_share\"] = bs_share\n",
    "\n",
    "\n",
    "    cust_share = []\n",
    "    bu_share = []\n",
    "    for i in range(len(x)):\n",
    "        cust_share.append((user_cat.loc[(x[\"product_category_name\"][i],x[\"customer_unique_id\"][i])]/order_cat_total[x[\"product_category_name\"][i]]))\n",
    "        bu_share.append((user_cat.loc[(x[\"product_category_name\"][i],x[\"customer_unique_id\"][i])]/user_cat_total[x[\"customer_unique_id\"][i]]))\n",
    "\n",
    "    x[\"cust_category_share\"] = cust_share\n",
    "    x[\"cat_cust_share\"] = bu_share\n",
    "\n",
    "    ### similarity\n",
    "    similarity = []\n",
    "    for i in range(len(x)):\n",
    "         similarity.append((np.dot([x[\"seller_category_share\"][i],x[\"cat_seller_share\"][i]] , [x[\"cust_category_share\"][i],x[\"cat_cust_share\"][i]])))\n",
    "        \n",
    "    x[\"similarity_using_cat\"] = similarity\n",
    "    ############################################################################################\n",
    "    ########### Total customers for each seller and total seller for each customer #############\n",
    "    dict_seller = pd.read_pickle('dict_seller.pkl')\n",
    "    dict_customer = pd.read_pickle('dict_customer.pkl')\n",
    "    dict_seller_order = pd.read_pickle(\"dict_seller_order.pkl\")\n",
    "    \n",
    "    num_customers = []\n",
    "    for i in range(len(x)):\n",
    "        num = dict_seller[x[\"seller_id\"][i]]\n",
    "        num_customers.append(num)\n",
    "    x[\"num_of_customers_for_seller\"] = num_customers\n",
    "    \n",
    "    num_sellers = []\n",
    "    for i in range(len(x)):\n",
    "        num = dict_customer[x[\"customer_unique_id\"][i]]\n",
    "        num_sellers.append(num)\n",
    "    x[\"num_of_sellers_for_cust\"] = num_sellers\n",
    "    \n",
    "        \n",
    "    num_orders = []\n",
    "    for i in range(len(x)):\n",
    "        num = dict_seller_order[x[\"seller_id\"][i]]\n",
    "        num_orders.append(num)\n",
    "\n",
    "    x[\"total_order_for_seller\"] = num_orders\n",
    "    \n",
    "#################################################################################################\n",
    "    label = joblib.load(\"seller_id_encode.pkl\")\n",
    "    x[\"seller_id_label\"] = label.transform(x[\"seller_id\"])\n",
    "    \n",
    "    label = joblib.load(\"product_id_encode.pkl\")\n",
    "    x[\"product_id_label\"] = label.transform(x[\"product_id\"])\n",
    "    #################################################\n",
    "    ############## countvectorizers ################\n",
    "    ### payment_type\n",
    "    vec = joblib.load(\"count_vect_payment_1.pkl\")\n",
    "    x_te_pay_type = vec.transform(x[\"payment_type\"].values)\n",
    "    #### order_item_id\n",
    "    x[\"order_item_id\"] = x[\"order_item_id\"].astype(str)\n",
    "    vec = joblib.load(\"count_vect_item_1.pkl\")\n",
    "    x_te_id = vec.transform(x[\"order_item_id\"].values)\n",
    "    ### product_category_name\n",
    "    vec = joblib.load(\"count_vect_cat_1.pkl\")\n",
    "    x_te_cat = vec.transform(x[\"product_category_name\"].values)\n",
    "    ####################################################\n",
    "    ############### standardization ####################\n",
    "    num = x[[\"payment_sequential\",\"payment_installments\",\"payment_value\",\"seller_id_label\",\"product_id_label\",\"seller_share\",\"bu_share\",\n",
    "              \"bs_share\",\"cust_share\",\n",
    "          \"lat_customer\",\"lng_customer\",\"lat_seller\",\"lng_seller\",\"product_name_lenght\",\"product_description_lenght\",\n",
    "           \"product_photos_qty\",\"product_weight_g\",\"size\",\"price\",\"delivery_day\",\"delivery_date\",\"delivery_month\",\n",
    "              \"delivery_hour\",\"purchased_day\",\"purchased_date\",\"purchased_month\",\"purchased_hour\",\"num_of_customers_for_seller\",\n",
    "              \"num_of_sellers_for_cust\",\"total_order_for_seller\",\n",
    "           \"freight_value\",\"estimated_time\",\"actual_time\",\"diff_actual_estimated\",\"diff_purchased_approved\",\n",
    "           \"diff_purchased_courrier\",\"distance\",\"speed\",\"similarity\",\"similarity_using_cat\"]]\n",
    "    \n",
    "    norm = joblib.load(\"std_num_1.pkl\")\n",
    "    x_te_num = norm.transform(num.values)\n",
    "    ######### binary features ###########\n",
    "    x_te_same_state = x.same_state.values.reshape(-1,1)\n",
    "    x_te_same_city = x.same_city.values.reshape(-1,1)\n",
    "    x_te_late_shipping = x.late_shipping.values.reshape(-1,1)\n",
    "    x_te_high_freight = x.high_freight.values.reshape(-1,1)\n",
    "    \n",
    "    #################################################################\n",
    "    ######## concatenate all features to create query point #########\n",
    "    test = hstack((x_te_pay_type,x_te_id,x_te_cat,x_te_num,x_te_same_state,\n",
    "                              x_te_same_city,x_te_late_shipping,x_te_high_freight)).toarray()\n",
    "    \n",
    "    ##################################################################\n",
    "    # array with zeros to store predicted target values\n",
    "    predicted_targets = np.zeros(shape=(y.shape))\n",
    "    \n",
    "    ind_1234 = [] #list of indices of points which are predicted to be 1,2,3,4\n",
    "    model = joblib.load(\"binary_model.pkl\")\n",
    "    prediction = model.predict(test)\n",
    "    for i,pred in enumerate(prediction):\n",
    "        if pred == 1:\n",
    "            predicted_targets[i]=5\n",
    "        else:\n",
    "            ind_1234.append(i) \n",
    "        \n",
    "        \n",
    "    x2 = x.loc[ind_1234]  # set which deosnot consists review_score 5\n",
    "    \n",
    "        ################ custom ensemble ##########################\n",
    "    label = joblib.load(\"seller_encode_2.pkl\")\n",
    "    x2[\"seller_id_enc\"] = label.transform(x2[\"seller_id\"])\n",
    "    \n",
    "    label = joblib.load(\"product_encode_2.pkl\")\n",
    "    x2[\"product_id_enc\"] = label.transform(x2[\"product_id\"])\n",
    "    ####\n",
    "    ############## countvectorizers ################\n",
    "    ### payment_type\n",
    "    vec = joblib.load(\"countvec_pay_2.pkl\")\n",
    "    x_te_pay_type = vec.transform(x2[\"payment_type\"].values)\n",
    "        \n",
    "    #### order_item_id\n",
    "    x2[\"order_item_id\"] = x2[\"order_item_id\"].astype(str)\n",
    "    vec = joblib.load(\"countvec_item_2.pkl\")\n",
    "    x_te_id = vec.transform(x2[\"order_item_id\"].values)\n",
    "        \n",
    "    ### product_category_name\n",
    "    vec = joblib.load(\"countvec_cat_2.pkl\")\n",
    "    x_te_cat = vec.transform(x2[\"product_category_name\"].values)\n",
    "        \n",
    "        ####################################################\n",
    "        ############### standardization ####################\n",
    "    num = x2[[\"payment_sequential\",\"payment_installments\",\"payment_value\",\"seller_id_enc\",\"product_id_enc\",\"seller_share\",\"bu_share\",\n",
    "                 \"bs_share\",\"cust_share\",\n",
    "                 \"lat_customer\",\"lng_customer\",\"lat_seller\",\"lng_seller\",\"product_name_lenght\",\"product_description_lenght\",\n",
    "                 \"product_photos_qty\",\"product_weight_g\",\"size\",\"price\",\"delivery_day\",\"delivery_date\",\"delivery_month\",\n",
    "                 \"delivery_hour\",\"purchased_day\",\"purchased_date\",\"purchased_month\",\"purchased_hour\",\"num_of_customers_for_seller\",\n",
    "                 \"num_of_sellers_for_cust\",\"total_order_for_seller\",\n",
    "                 \"freight_value\",\"estimated_time\",\"actual_time\",\"diff_actual_estimated\",\"diff_purchased_approved\",\n",
    "                 \"diff_purchased_courrier\",\"distance\",\"speed\",\"similarity\",\"similarity_using_cat\"]]\n",
    "    \n",
    "    norm = joblib.load(\"std_num_2.pkl\")\n",
    "    x_te_num = norm.transform(num)\n",
    "    ####### binary features #######\n",
    "    x_te_same_state = x2.same_state.values.reshape(-1,1)\n",
    "    x_te_same_city = x2.same_city.values.reshape(-1,1)\n",
    "    x_te_late_shipping = x2.late_shipping.values.reshape(-1,1)\n",
    "    x_te_high_freight = x2.high_freight.values.reshape(-1,1)\n",
    "    \n",
    "    \n",
    "            #################################################################\n",
    "    ######## concatenate all features to create query point #########\n",
    "    test2 = hstack((x_te_pay_type,x_te_id,x_te_cat,x_te_num,x_te_same_state,\n",
    "                              x_te_same_city,x_te_late_shipping,x_te_high_freight)).toarray()\n",
    "    \n",
    "    models = joblib.load(\"base_models.pkl\")\n",
    "    predicts = []     \n",
    "    for model in models:\n",
    "        predicts.append(model.predict(test2))\n",
    "        \n",
    "    predicts = np.array(predicts).reshape(-1,150)\n",
    "        \n",
    "    meta_clf = joblib.load(\"meta_clf.pkl\")\n",
    "    \n",
    "    prediction = meta_clf.predict(predicts)\n",
    "     \n",
    "    for i,j in enumerate(ind_1234):\n",
    "        predicted_targets[j] = prediction[i]\n",
    "        \n",
    "#########################################################################################################################\n",
    "################ Calculation of Macro F1 score ##########################################################################    \n",
    "    \n",
    "    macro_f1 = f1_score(y,predicted_targets,average=\"macro\",labels=[1,2,3,4,5])\n",
    "    \n",
    "    return macro_f1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
